{
  
    
        "post0": {
            "title": "1-1. 머신러닝을 위한 주가 데이터셋 생성",
            "content": "1. Stock Prediction Part.1 - baseline model . 1-1. &#47672;&#49888;&#47084;&#45789;&#51012; &#50948;&#54620; &#51452;&#44032; &#45936;&#51060;&#53552;&#49483; &#49373;&#49457; . 주가 데이터셋 생성 절차는 df2list - dictionary - MultiProcessing - MySQL 순서로 진행한다. 4가지 절차를 통해 데이터셋이 달라지는 것은 아니고, 속도를 개선시키는 방향으로의 효율적인 코드를 짜기 위한 훈련 과정이다. 대규모 데이터셋을 다루기 위해서는 효율적인 코딩을 통해 속도를 개선하는 것도 중요한 일이다. 특히 이번에 사용하는 주가 데이터셋은 양이 많을 뿐만 아니라, fdr 라이브러리를 사용하여 외부에서 불러와야하기 때문에 데이터셋을 구성하는 것만 해도 속도가 상당히 느리다. 이러한 문제점을 해결하고자 본 포스팅에서는 4단계에 걸친 데이터셋 생성 과정을 보여준다. . . &#45936;&#51060;&#53552;&#49483; &#51221;&#51032; . 조건: 전체 약 2000개 종목 중 2018년 부터 존속하였던 기업 중 거래대금이 1000억 이상 발생한 날짜 (거래대금은 추후에 수정 가능) | column: 조건 에서 선별한 특정 날짜를 D0라고 했을 때, D-9, D-8, ..., D0, 총 10일 치의 Open, High, Low, Close, 거래대금(trading_value) | label: 조건에 부합하는 특정 날짜(D0) 대비 다음날(D+1) 날짜의 종가(close)가 2%이상 상승하면 1, 상승하지 않으면 0 | train dataset: 2018년 1월 2일 - 2020년 12월 31일 (2년) | test dataset: 2021년 1월 2일 ~ 2021년 6월 31일 (6개월) | . . &#45936;&#51060;&#53552;&#49483; &#49373;&#49457; &#44284;&#51228; . 데이터셋 생성을 총 3가지 과제로 나누어 진행한다. . 과제 I: 종목 리스트 생성-2018년 부터 존속하였던 기업(상장일 2018년 1월 1일 이전 기업) 선별 | 과제 II: 과제I 의 기업 중 거래대금이 1000억 이상 발생했던 특정 날짜 선별 (거래대금=거래량X종가 로 계산) | 과제 III: 과제II 의 날짜에 대해 최종 머신러닝 데이터 생성 | . . &#47785;&#52264; . (0) Finance Data Reader를 이용한 주가 데이터셋 - DataFrame | (1) Finance Data Reader를 이용한 주가 데이터셋 - df2list | (2) Finance Data Reader를 이용한 주가 데이터셋 - dictionary | (3) Finance Data Reader를 이용한 주가 데이터셋 - MultiProcessing | (4) Finance Data Reader를 이용한 주가 데이터셋 - MySQL | (5) 최종 머신러닝 데이터셋 | . &#54596;&#50836; &#46972;&#51060;&#48652;&#47084;&#47532; import . # ! pip install -U finance-datareader . import pandas as pd import os from tqdm import tqdm import FinanceDataReader as fdr import time # 경고 메시지 무시 import warnings warnings.filterwarnings(action=&#39;ignore&#39;) . &#10004;&#65039; (0) Finance Data Reader&#47484; &#51060;&#50857;&#54620; &#51452;&#44032; &#45936;&#51060;&#53552;&#49483; - DataFrame . 속도 비교를 위해 기존 데이터의 타입인 DataFrame을 사용하여 데이터셋을 생성한다. 연구 인턴 초기 첫번째로 작성했던 코드들인데, 개선해야 할 부분들이 많다. . 과제 I . df = pd.read_html(&#39;http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&#39;, header=0)[0] # 회사명, 종목코드, 상장일 컬럼만 사용 df_code = df[[&#39;회사명&#39;, &#39;종목코드&#39;, &#39;상장일&#39;]] # 종목코드를 6자리로 맞춰 준다. df_code[&#39;종목코드&#39;] = df_code[&#39;종목코드&#39;].apply(lambda x : str(x).zfill(6)) display(df_code.head(3)) print() # 상장일이 2018년 1월 1일 이전인 종목코드 선별 start_time = time.time() lst_code = df_code.loc[df_code[&#39;상장일&#39;] &lt; &#39;2018-01-01&#39;, &#39;종목코드&#39;].to_list() print(&quot;걸린 시간: &quot;, time.time() - start_time) print() print(&#39;상장일 2018-01-01 이전 종목코드: &#39;, lst_code[:5]) print() print(f&#39;총 {len(df_code)} 개의 종목 중 {len(lst_code)} 개의 종목 선별&#39;) . 회사명 종목코드 상장일 . 0 DL | 000210 | 1976-02-02 | . 1 DRB동일 | 004840 | 1976-05-21 | . 2 DSR | 155660 | 2013-05-15 | . 걸린 시간: 0.0006933212280273438 상장일 2018-01-01 이전 종목코드: [&#39;000210&#39;, &#39;004840&#39;, &#39;155660&#39;, &#39;078930&#39;, &#39;001390&#39;] 총 2507 개의 종목 중 1977 개의 종목 선별 . 과제 II . stock_dict = {} for code in tqdm(lst_code): stock = fdr.DataReader(code, start=&#39;20180101&#39;, end=&#39;20201231&#39;) stock[&#39;trading&#39;] = stock[&#39;Volume&#39;] * stock[&#39;Close&#39;] # 거래대금 컬럼 추가 if sum(stock[&#39;trading&#39;] &gt;= 100000000000) &gt;= 1: # 거래대금이 1000억 이상인 데이터가 하나 이상 존재하면 stock_dict[code] = stock[stock[&#39;trading&#39;] &gt;= 100000000000].index print(f&#39;총 {len(lst_code)} 개의 종목 중 {len(stock_dict)} 개의 종목 사용&#39;) . 100%|██████████████████████████████████████████████| 1977/1977 [02:58&lt;00:00, 11.08it/s] . 총 1977 개의 종목 중 799 개의 종목 사용 . . lst_code_date = [] for code in tqdm(stock_dict): for date in (stock_dict[code]): lst_code_date.append([code, date]) print(f&#39;선별된 날짜는 총 {len(lst_code_date)}개&#39;) . 100%|█████████████████████████████████████████████| 799/799 [00:00&lt;00:00, 13125.89it/s] . 선별된 날짜는 총 14182개 . . 과제 III . data_dict = {&#39;code&#39;: [], &#39;d0&#39;: [], &#39;info&#39;: [], &#39;up&#39;: []} for code, date in tqdm(lst_code_date): start_date = &#39;20171201&#39; # 2018년 초반 날짜가 D0라면 2017년 데이터 필요 (D-9~D-1) end_date = &#39;20210130&#39; # 2020년 후반 날짜가 D0라면 2021년 데이터 필요 (D+1) stock = fdr.DataReader(code, start = start_date, end = end_date) stock.reset_index(inplace=True) # &#39;Date&#39; index -&gt; column D9_index = stock[stock[&#39;Date&#39;] == str(date)].index[0] - 9 # D-9 날짜의 인덱스 next_index = stock[stock[&#39;Date&#39;] == str(date)].index[0] + 1 # D+1 날짜의 인덱스 # 종목코드 (code) data_dict[&#39;code&#39;].append(code) # 기준일 (d0) data_dict[&#39;d0&#39;].append(date) # D-9 ~ D+1, 총 11일치의 sub stock DataFrame 생성 sub_stock = stock.iloc[D9_index:next_index+1] sub_stock[&#39;trading&#39;] = sub_stock[&#39;Close&#39;] * sub_stock[&#39;Volume&#39;] # 거래대금 컬럼 추가 # 10일 간의 데이터 (info) info_list = [] for i in range(10): info_list.append(sub_stock.iloc[i, [1, 2, 3, 4, -1]].to_list()) remove_list=[&#39;[&#39;, &#39;]&#39;] for i in range(2): info_list = f&#39;{info_list}&#39;.replace(remove_list[i], &#39;&#39;) data_dict[&#39;info&#39;].append(info_list) # D+1 종가 2% 상승 여부 (up) up = sub_stock.iloc[-2][&#39;Close&#39;] + 0.02 * sub_stock.iloc[-2][&#39;Close&#39;] if sub_stock.iloc[-1][&#39;Close&#39;] &gt;= up: data_dict[&#39;up&#39;].append(1) else: data_dict[&#39;up&#39;].append(0) . 100%|████████████████████████████████████████████| 14182/14182 [17:08&lt;00:00, 13.78it/s] . df_result = pd.DataFrame(data_dict) display(df_result.head()) # 최종 결과 데이터셋 txt 파일 저장 df_result.to_csv(&quot;assignment3.txt&quot;) print(f&#39;생성된 데이터의 개수는 {len(pd.read_csv(&quot;assignment3.txt&quot;))} 개&#39;) . code d0 info up . 0 000210 | 2018-01-26 | 78343, 78614, 76987, 77892, 9590608284, 77801,... | 0 | . 1 000210 | 2018-08-08 | 68855, 69397, 67590, 69036, 6067435968, 69487,... | 0 | . 2 000210 | 2020-04-02 | 44819, 52951, 44322, 51145, 15615437965, 47439... | 0 | . 3 000210 | 2020-09-11 | 80783, 84487, 78524, 78524, 61554885076, 79608... | 0 | . 4 000210 | 2020-12-11 | 76174, 76174, 72289, 72289, 76043112348, 72831... | 0 | . 생성된 데이터의 개수는 14182 개 . 개선해야할 사항 . 속도 개선: 과제III 은 약 17분이 걸린 것을 보아 속도 면에서 상당히 비효율적이었다는 것을 알 수 있다. (거래대금을 10억으로 설정했을 때 1% 진행에 5분이 걸렸다. 그럼 총 500분이 걸릴 것으로 예상할 수 있다.) | . # 10일 간의 데이터 부분: info_list에 데이터를 추가하는 과정에서 억지로 포맷을 맞추기 위해 불필요한 for문이 들어갔다. | . # D+1 종가 2% 상승 여부 부분: 전 날 대비 2% 상승율을 직접 계산해 주었는데, 이미 변화율이 계산 되어 있는 change라는 컬럼을 사용하는 것으로 대체한다. | . txt 파일 저장: DataFrame으로 생성을 한 후에 txt 파일로 저장했는데, 데이터 생성 시 파일 입출력 write()를 사용해서 바로 txt 파일로 저장하는 방식으로 변경한다. | . . &#10004;&#65039; (1) Finance Data Reader&#47484; &#51060;&#50857;&#54620; &#51452;&#44032; &#45936;&#51060;&#53552;&#49483; - df2list . 첫번째 방법은 DataFrame 사용을 지양하고, python의 기본 데이터 타입인 list로 바꾸어 사용하는 방법이다. 이로써 column 중심의 연산을 row 중심의 연산으로 바꾸어준다. 이 방법에서는 속도 개선 보다는 (0)번 방법의 코드에서 효율적이지 못했던 부분을 고치고 깔끔한 코드로 보완한다. . 과제 I . display(df_code.head(2)) # 🌟 dataframe -&gt; list lst_stock = df_code.values.tolist() print(lst_stock[:2]) print() lst_code = [] # 선별 된 코드를 담을 리스트 start_time = time.time() for row in lst_stock: code, date = row[1], row[2] if date &lt;= &#39;2018-01-01&#39;: lst_code.append(code) print(&quot;걸린 시간: &quot;, time.time() - start_time) print() print(&#39;상장일 2018-01-01 이전 종목코드: &#39;, lst_code[:4]) print() print(f&#39;총 {len(df_code)} 개의 종목 중 {len(lst_code)} 개의 종목 선별&#39;) . 회사명 종목코드 상장일 . 0 DL | 000210 | 1976-02-02 | . 1 DRB동일 | 004840 | 1976-05-21 | . [[&#39;DL&#39;, &#39;000210&#39;, &#39;1976-02-02&#39;], [&#39;DRB동일&#39;, &#39;004840&#39;, &#39;1976-05-21&#39;]] 걸린 시간: 0.0004284381866455078 상장일 2018-01-01 이전 종목코드: [&#39;000210&#39;, &#39;004840&#39;, &#39;155660&#39;, &#39;078930&#39;] 총 2507 개의 종목 중 1977 개의 종목 선별 . 과제 II . lst_code_date = [] for code in tqdm(lst_code): stock = fdr.DataReader(code, start=&#39;20180102&#39;, end=&#39;20201231&#39;) stock.reset_index(inplace=True) # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() for row in lst_stock: date, trading_value = row[0], row[4]*row[5] if trading_value &gt;= 100000000000: # 거래대금 1000억 이상 lst_code_date.append([code, date.date().strftime(&quot;%Y%m%d&quot;)]) print(f&#39;선별된 날짜는 총 {len(lst_code_date)}개&#39;) . 100%|██████████████████████████████████████████████| 1977/1977 [02:55&lt;00:00, 11.26it/s] . 선별된 날짜는 총 14182개 . . 과제 III . OF = open(&#39;assignment3.txt&#39;,&#39;w&#39;) for code, date in tqdm(lst_code_date): start_date = &#39;20180101&#39; end_date = &#39;20201231&#39; stock = fdr.DataReader(code, start = start_date, end = end_date) stock.reset_index(inplace=True) # &#39;Date&#39; index -&gt; column # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() for idx, row in enumerate(lst_stock): if (idx &lt; 9) or (idx &gt;= len(lst_stock)-1): # 예외 처리 continue if row[0].date().strftime(&quot;%Y%m%d&quot;) == date: # D-9 ~ D0 데이터만 담기 sub_stock = lst_stock[idx-9:idx+1] # 10일 간의 데이터 lst_info = [] for row2 in sub_stock: lst_prices, trading_value = row2[1:5], row[4]*row[5] lst_info += lst_prices + [trading_value] info = &#39;,&#39;.join(map(str, lst_info)) # D+1 종가 2% 상승 여부 (up) change = lst_stock[idx+1][6] label = int(change &gt;= 0.02) # 저장 OF.write(f&#39;{code} t{date} t{lst_info} t{label} n&#39;) OF.close() print(f&#39;생성된 데이터의 개수는 {len(pd.read_csv(&quot;assignment3.txt&quot;))} 개&#39;) . 100%|████████████████████████████████████████████| 14182/14182 [17:43&lt;00:00, 13.33it/s] . 생성된 데이터의 개수는 13939 개 . . OF.write()를 사용함으로써 블필요한 DataFrame 을 생성하지 않는다. | . # 10일간의 데이터 부분은 join() 함수를 사용하여 불필요한 for문 사용을 줄였고, # D+1 종가 2% 상승 여부 (up) 부분은 전날 대비 종가 변화율을 계산하지 않고 change 컬럼을 활용하는 것으로 바꾸었다. | . 속도에 대한 문제점 : 전 보다 깔끔한 코드로 보완이 되었지만, 아직 속도에 대한 문제점이 남아있다. 속도를 개선하기 위해서는 fdr 라이브러리를 최소한으로 사용해야 한다. 이를 해결하기 위해 dictionary를 사용하는 방법으로 넘어간다. | . . &#10004;&#65039; (2) Finance Data Reader&#47484; &#51060;&#50857;&#54620; &#51452;&#44032; &#45936;&#51060;&#53552;&#49483; - dictionary . dictionary를 사용하는 방법은 과제III 의 속도를 개선한다. fdr 라이브러리를 최소한으로 사용하고, for문을 최대한 줄인다. 현재 문제점은 날짜를 기준으로 for문이 돌아가기 때문에 같은 데이터(같은 종목)가 여러번 불러와지는 경우가 다수 존재한다는 것이다. 따라서 과제II 에서 code별 D0 날짜 리스트를 dictionary 타입으로 생성하고, 과제III 에서 code 당 한번만 fdr 라이브러리를 사용하도록 바꾸어 준다. . 과제 I . 과제I 은 앞의 방법과 같으므로 생략한다. . print(&#39;상장일 2018-01-01 이전 종목코드: &#39;, lst_code[:4]) print() print(f&#39;총 {len(df_code)} 개의 종목 중 {len(lst_code)} 개의 종목 선별&#39;) . 상장일 2018-01-01 이전 종목코드: [&#39;000210&#39;, &#39;004840&#39;, &#39;155660&#39;, &#39;078930&#39;] 총 2507 개의 종목 중 1977 개의 종목 선별 . 과제 II . dict_code2date = {} for code in tqdm(lst_code): start_date = &#39;20180102&#39; end_date = &#39;20201231&#39; stock = fdr.DataReader(code, start = start_date, end = end_date) stock.reset_index(inplace=True) # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() for row in lst_stock: date, trading_value = row[0], row[4]*row[5] if trading_value &gt;= 100000000000: if code not in dict_code2date.keys(): dict_code2date[code] = [date.date().strftime(&quot;%Y%m%d&quot;)] else: dict_code2date[code].append(date.date().strftime(&quot;%Y%m%d&quot;)) print(f&#39;총 {len(lst_code)} 개의 종목 중 {len(dict_code2date)} 개의 종목 사용&#39;) . 100%|██████████████████████████████████████████████| 1977/1977 [02:42&lt;00:00, 12.14it/s] . 총 1977 개의 종목 중 799 개의 종목 사용 . . 과제 III . OF = open(&#39;assignment3.txt&#39;, &#39;w&#39;) for code in tqdm(dict_code2date): # code의 stock start_date = &#39;20180101&#39; end_date = &#39;20201231&#39; stock = fdr.DataReader(code, start = start_date, end = end_date) stock.reset_index(inplace=True) # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() for idx, row in enumerate(lst_stock): if (idx &lt; 9) or (idx &gt;= len(lst_stock)-1): # 예외 처리 continue date = row[0].date().strftime(&quot;%Y%m%d&quot;) if date not in dict_code2date[code]: # 조건에 부합하는 날짜 (D0 날짜)를 발견할 때까지 continue continue # D-9 ~ D0 데이터만 담기 sub_stock = lst_stock[idx-9:idx+1] # 10일간의 데이터 lst_info = [] for row2 in sub_stock: lst_prices, trading_value = row2[1:5], row2[4]*row2[5] lst_info += lst_prices + [trading_value] info = &#39;,&#39;.join(map(str, lst_info)) # D+1 종가 2% 상승 여부 label = int(lst_stock[idx+1][6] &gt;= 0.02) # 저장 OF.write(f&#39;{code} t{date} t{info} t{label} n&#39;) OF.close() print(f&#39;생성된 데이터의 개수는 {len(pd.read_csv(&quot;assignment3.txt&quot;))} 개&#39;) . 100%|████████████████████████████████████████████████| 799/799 [01:07&lt;00:00, 11.84it/s] . 생성된 데이터의 개수는 13939 개 . . 약 17분이 걸리던 시간이 1분으로 줄어들었다. . . &#10004;&#65039; (3) Finance Data Reader&#47484; &#51060;&#50857;&#54620; &#51452;&#44032; &#45936;&#51060;&#53552;&#49483; - MultiProcessing . multi processing(다중 처리): 컴퓨터 시스템 한 대에 두개 이상의 중앙 처리 장치 (CPU) 를 이용하여 병렬처리하는 것 | . python multi processing 문서: https://docs.python.org/ko/3/library/multiprocessing.html. | . python은 multiprocessing 라이브러리를 통해 다중 처리를 지원한다. 여러 개의 코어를 연산에 사용함으로써 많은 작업을 빠른 시간에 처리해줄 수 있다는 장점이 있다. . [ core=10으로 설정하여 multi processing을 수행할 때 코어 사용 ] . import time, os from multiprocessing import Pool . 과제 I . 과제I 은 앞의 방법과 같으므로 생략한다. . print(&#39;상장일 2018-01-01 이전 종목코드: &#39;, lst_code[:4]) print() print(f&#39;총 {len(df_code)} 개의 종목 중 {len(lst_code)} 개의 종목 선별&#39;) . 상장일 2018-01-01 이전 종목코드: [&#39;000210&#39;, &#39;004840&#39;, &#39;155660&#39;, &#39;078930&#39;] 총 2507 개의 종목 중 1977 개의 종목 선별 . 과제 II . multi processing을 위한 함수 정의 | . def make_lst_result(code): start_date = &#39;20180101&#39; end_date = &#39;20201231&#39; lst_date = [] stock = fdr.DataReader(code, start = start_date, end = end_date) stock.reset_index(inplace=True) # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() for row in lst_stock: if row[4] * row[5] &gt;= 100000000000: lst_date.append(row[0].date().strftime(&quot;%Y%m%d&quot;)) return [code, lst_date] . multi processing 수행 | . start_time = time.time() num_cores = 10 pool = Pool(num_cores) lst_code_date = pool.map(make_lst_result, lst_code) pool.close() pool.join() print(time.time() - start_time) . 17.97966194152832 . 앞서 약 2분 40초 가 걸렸던 과제II 를 multi processing을 사용하여 17초대로 단축시켰다. . dictionary 생성 | . dict_code2date = {} for code, lst_date in tqdm(lst_code_date): if lst_date == []: continue dict_code2date[code] = lst_date print(f&#39;총 {len(lst_code)} 개의 종목 중 {len(dict_code2date)} 개의 종목 사용&#39;) . 100%|█████████████████████████████████████████| 1977/1977 [00:00&lt;00:00, 1610124.08it/s] . 총 1977 개의 종목 중 799 개의 종목 사용 . . 과제 III . multi processing을 위한 함수 정의 | . def make_lst_result2(code): # code의 stock start_date = &#39;20180101&#39; end_date = &#39;20201231&#39; stock = fdr.DataReader(code, start = start_date, end = end_date) stock.reset_index(inplace=True) # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() lst_result = [] for idx, row in enumerate(lst_stock): if (idx &lt; 9) or (idx &gt;= len(lst_stock)-1): # 예외 처리 continue date = row[0].date().strftime(&quot;%Y%m%d&quot;) if date not in dict_code2date[code]: # 조건에 부합하는 날짜 (D0 날짜)를 발견할 때까지 continue continue # D-9 ~ D0 데이터만 담기 sub_stock = lst_stock[idx-9:idx+1] # 10일간의 데이터 lst_info = [] for row2 in sub_stock: lst_prices, trading_value = row2[1:5], row2[4]*row2[5] lst_info += lst_prices + [trading_value] info = &#39;,&#39;.join(map(str, lst_info)) # D+1 종가 2% 상승 여부 label = int(lst_stock[idx+1][6] &gt;= 0.02) lst_result.append([code, date, info, label]) return lst_result . multi processing 수행 | . start_time = time.time() num_cores = 10 pool = Pool(num_cores) lst_data = pool.map(make_lst_result2, dict_code2date.keys()) pool.close() pool.join() print(time.time() - start_time) . 8.186521768569946 . 앞서 진행했던 방법에서 1분이 걸렸던 작업이 multi processing을 통하여 8초로 줄어들었다. . txt 파일 생성 | . OF = open(&quot;assignment3_multi_processing.txt&quot;, &#39;w&#39;) for row in lst_data: for num in range(len(row)): OF.write(&#39; t&#39;.join(map(str, row[num])) + &#39; n&#39;) OF.close() print(f&#39;생성된 데이터의 개수는 {len(pd.read_csv(&quot;assignment3_multi_processing.txt&quot;))} 개&#39;) . 생성된 데이터의 개수는 13939 개 . . &#10004;&#65039; (4) Finance Data Reader&#47484; &#51060;&#50857;&#54620; &#51452;&#44032; &#45936;&#51060;&#53552;&#49483; - MySQL . 4번째 방법은 MySQL을 사용한다. 외부 데이터를 불러오지 않아도 되고, 서버 DB에 저장된 데이터를 불러오는 것이므로 multi processing을 사용하지 않고도 빠른 속도로 데이터셋을 생성할 수 있다. . 과제 I . 최종적으로 머신러닝 분석에 사용할 데이터셋은 코스피, 코스닥 시장에 해당하는 종목들만을 사용한다. 현재 db에 저장되어 있는 데이터도 코스피, 코스닥 시장에 해당하는 종목들이 입력되어 있으며, 해당 종목들을 추린 code_list.txt에서 종목들을 불러와 lst_code를 사용한다. . IF = open(&#39;../data/code_list.txt&#39;) lst_code = IF.readlines() print(f&#39;총 {len(df_code)} 개의 종목 중 {len(lst_code)} 개의 종목 선별&#39;) . 총 2507 개의 종목 중 1561 개의 종목 선별 . # ! pip install pymysql import pymysql from sqlalchemy import create_engine . MySQL 데이터 저장 (dataframe -&gt; sql) | . code 별로 다른 테이블에 저장한다. . db_connection_str = &#39;mysql+pymysql://[db username]:[db password]@[host address]/[db name]&#39; db_connection = create_engine(db_connection_str) conn = db_connection.connect() for code in tqdm(lst_code): start_date = &#39;20170101&#39; end_date = &#39;20211231&#39; stock = fdr.DataReader(code, start = start_date, end = end_date) stock = stock.reset_index() stock = stock[[&#39;Date&#39;, &#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close&#39;, &#39;Volume&#39;, &#39;Change&#39;]] stock.to_sql(name=f&#39;stock_{code}&#39;, con=db_connection, if_exists=&#39;fail&#39;, index=False) . MySQL 에서 데이터 불러온 후 데이터셋 생성 | . db_dsml = pymysql.connect( host = &#39;localhost&#39;, port = 3306, user = &#39;[db username]&#39;, passwd = &#39;[db password]&#39;, db = &#39;[db name]&#39;, charset = &#39;utf8&#39; ) cursor = db_dsml.cursor() . 과제 II . dict_code2date = {} for code in tqdm(lst_code): code = code.strip() sql_query = &#39;&#39;&#39; SELECT * FROM stock_{} WHERE Date BETWEEN &#39;2018-01-01&#39; AND &#39;2020-12-31&#39; &#39;&#39;&#39;.format(code) stock = pd.read_sql(sql = sql_query, con = db_dsml) # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() for row in lst_stock: date, trading_value = row[0], row[4]*row[5] if trading_value &gt;= 100000000000: if code not in dict_code2date.keys(): dict_code2date[code] = [date.date().strftime(&quot;%Y%m%d&quot;)] else: dict_code2date[code].append(date.date().strftime(&quot;%Y%m%d&quot;)) print(f&#39;총 {len(lst_code)} 개의 종목 중 {len(dict_code2date)} 개의 종목 사용&#39;) . 100%|██████████████████████████████████████████████| 1561/1561 [00:22&lt;00:00, 69.07it/s] . 총 1561 개의 종목 중 679 개의 종목 사용 . . 과제 III . OF = open(&#39;assignment3_sql.txt&#39;, &#39;w&#39;) for code in tqdm(dict_code2date): code = code.strip() sql_query = &#39;&#39;&#39; SELECT * FROM stock_{} WHERE Date BETWEEN &#39;2018-01-01&#39; AND &#39;2020-12-31&#39; &#39;&#39;&#39;.format(code) stock = pd.read_sql(sql = sql_query, con = db_dsml) # 🌟 dataframe -&gt; list lst_stock = stock.values.tolist() for idx, row in enumerate(lst_stock): if (idx &lt; 9) or (idx &gt;= len(lst_stock)-1): # 예외 처리 continue date = row[0].date().strftime(&quot;%Y%m%d&quot;) if date not in dict_code2date[code]: # 조건에 부합하는 날짜 (D0 날짜)를 발견할 때까지 continue continue # D-9 ~ D0 데이터만 담기 sub_stock = lst_stock[idx-9:idx+1] # 10일간의 데이터 lst_info = [] for row2 in sub_stock: lst_prices, trading_value = row2[1:5], row2[4]*row2[5] lst_info += lst_prices + [trading_value] info = &#39;,&#39;.join(map(str, lst_info)) # D+1 종가 2% 상승 여부 label = int(lst_stock[idx+1][6] &gt;= 0.02) # 저장 OF.write(f&#39;{code} t{date} t{info} t{label} n&#39;) OF.close() print(f&#39;생성된 데이터의 개수는 {len(pd.read_csv(&quot;assignment3_sql.txt&quot;))} 개&#39;) . 100%|████████████████████████████████████████████████| 679/679 [00:11&lt;00:00, 61.46it/s] . 생성된 데이터의 개수는 11934 개 . . . &#10004;&#65039; (5) &#52572;&#51333; &#47672;&#49888;&#47084;&#45789; &#45936;&#51060;&#53552;&#49483; . 최종적으로 생성된 머신러닝 데이터셋의 형태를 확인한다. . IF=open(&quot;assignment3_sql.txt&quot;,&#39;r&#39;) lst_code_date=[] trainX=[] trainY=[] for line in IF: code, date, x, y = line.strip().split(&quot; t&quot;) lst_code_date.append([code, date]) trainX.append(list(map(int, x.split(&quot;,&quot;)))) trainY.append(int(y)) trainX=pd.DataFrame(trainX) trainY=pd.DataFrame(trainY) . print(&quot;===== trainX =====&quot;) print(&quot;trainX shape:&quot;, trainX.shape) display(trainX.head()) print() print(&quot;===== trainY =====&quot;) print(&quot;trainY shape:&quot;, trainY.shape) display(trainY.head()) . ===== trainX ===== trainX shape: (11935, 50) . 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49 . 0 10250 | 12050 | 10150 | 11800 | 307823874200 | 11950 | 12450 | 10900 | 11750 | 240410569500 | ... | 15300 | 15400 | 12650 | 13700 | 789063638200 | 13700 | 16100 | 13400 | 15400 | 897154258000 | . 1 11950 | 12450 | 10900 | 11750 | 240410569500 | 11850 | 14150 | 11600 | 12600 | 764364560400 | ... | 13700 | 16100 | 13400 | 15400 | 897154258000 | 14700 | 15500 | 14000 | 14350 | 277027065700 | . 2 11850 | 14150 | 11600 | 12600 | 764364560400 | 12800 | 13200 | 12000 | 12200 | 170010147600 | ... | 14700 | 15500 | 14000 | 14350 | 277027065700 | 13050 | 13300 | 11650 | 11650 | 231873876050 | . 3 12800 | 13200 | 12000 | 12200 | 170010147600 | 12450 | 13400 | 12350 | 12850 | 211661434950 | ... | 13050 | 13300 | 11650 | 11650 | 231873876050 | 12200 | 13150 | 11600 | 12200 | 222393934200 | . 4 12450 | 13400 | 12350 | 12850 | 211661434950 | 12800 | 12950 | 11300 | 11700 | 91801277100 | ... | 12200 | 13150 | 11600 | 12200 | 222393934200 | 12200 | 13750 | 12100 | 12350 | 256196958550 | . 5 rows × 50 columns . ===== trainY ===== trainY shape: (11935, 1) . 0 . 0 0 | . 1 0 | . 2 1 | . 3 0 | . 4 1 | . kospi + kosdaq 주식 시장, 3년 이상 존속하였던 종목들을 거래대금 1000억 이상의 조건으로 설정하고, 10일 간의 데이터들을 feature로 두어 생성한 최종 머신러닝 데이터셋은 11935 X 50 의 크기가 나왔다. | . . 4단계의 과정을 거쳐 머신러닝 데이터셋 생성을 마쳤다. 다음 글에서는 생성된 머신러닝 데이터셋을 사용하여 여러 머신러닝 모델을 학습 및 평가하여 성능이 가장 좋은 모델을 선정하는 baseline model selection을 진행한다. .",
            "url": "https://eunsukim06.github.io/blog/stock%20prediction/2022/07/07/stock-dataset.html",
            "relUrl": "/stock%20prediction/2022/07/07/stock-dataset.html",
            "date": " • Jul 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://eunsukim06.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://eunsukim06.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://eunsukim06.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://eunsukim06.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}